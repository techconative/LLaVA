# Welcome to the LLaVA DSL Gen Project Wiki

## Table of Contents
- [Introduction](#introduction)
- [Installation](#installation)
- [Usage](#usage)
- [Contributing](#contributing)
- [FAQ](#faq)

## Introduction
Welcome to the LLaVA DSL Gen Project! This project is designed to demonstrate how to install and navigate through this repository.

## Installation

### Step-by-Step LLaVA Installation Guide from the Github Repository

1. **Clone this repository and navigate to the LLaVA folder:**
    ```shell
    git clone https://github.com/haotian-liu/LLaVA.git
    cd LLaVA
    ```

2. **Install Package:**
    ```shell
    conda create -n llava python=3.10 -y
    conda activate llava
    pip install --upgrade pip  # enable PEP 660 support
    pip install -e .
    ```

3. **Install additional packages for training cases:**
    ```shell
    pip install -e ".[train]"
    pip install flash-attn --no-build-isolation
    ```

_For the purpose of running the current codes use the llava_new venev._

### Finetuning Guide
To start finetuning, run the _LLaVA/scripts/v1_5/finetune_task_lora.sh_ with the desired hyperparameter settings. 

### Data Preperation Guide
In addition to existing steps, the current repository also offers additional feature to split your data into train_eval_test split according to your desired split ratio. Follow the below steps for the same.
1. _  



## Usage
After installation, you can start the project with:
```bash
npm start

_
